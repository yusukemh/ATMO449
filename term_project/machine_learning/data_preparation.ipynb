{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2674b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import matplotlib.pyplot as plt\n",
    "base_dir = f'/mnt/lustre/koa/class/atmo449_class/students/team_1_flood_risk/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17779b8",
   "metadata": {},
   "source": [
    "# Rainfall data\n",
    "\n",
    "subhourly -> hourly is done by mean aggregation. Only keep data if all 4 timestamps exist.<br>\n",
    "hourly -> 3 hourly is done by max aggregation. Keep data if any timestamp exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d48e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_data = pd.read_csv(f\"{base_dir}/raw_data/station_metadata.csv\")\n",
    "available_station_ids = [int(i.split('.')[0]) for i in os.listdir(f\"{base_dir}/preprocessed_data/selected_flowgauge_15mins\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc519071",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregation = 'mean'\n",
    "temp_res = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce6397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                 | 0/32 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for station_id in tqdm(available_station_ids):\n",
    "    df_obs = pd.read_csv(f\"{base_dir}/preprocessed_data/selected_flowgauge_15mins/{station_id}.csv\")\n",
    "    df_obs['hst_timestamp'] = pd.to_datetime(df_obs['hst_timestamp'])\n",
    "    df_obs = df_obs.set_index('hst_timestamp', drop=True)\n",
    "    df_obs_hourly_means_all = df_obs.resample('h').mean()\n",
    "    df_obs_hourly_means = df_obs_hourly_means_all[(df_obs.groupby(pd.Grouper(freq='h')).size() == 4)]\n",
    "\n",
    "    if temp_res == 1: # in this case aggregation does not matter\n",
    "        df_obs_hourly_means.to_csv(f\"{base_dir}/preprocessed_data/selected_flowgauge_1hourly/{station_id}.csv\")\n",
    "        continue\n",
    "\n",
    "    # this is ignored if temp_res == 1\n",
    "    if aggregation == 'mean':\n",
    "        df_3hourly = df_obs_hourly_means.resample('3h', closed='left').mean()\n",
    "    else:\n",
    "        df_3hourly = df_obs_hourly_means.resample('3h', closed='left').max()\n",
    "    df_3hourly.to_csv(f\"{base_dir}/preprocessed_data/selected_flowgauge_3hourly/{aggregation}/{station_id}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc2dfe8",
   "metadata": {},
   "source": [
    "# ERA5 data\n",
    "\n",
    "Regrid, resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5044a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gcm = xr.open_dataset(f\"{base_dir}/raw_data/GFDL/GFDL_CM4C192_pr_hawaii_2007_2014.nc\")\n",
    "output_grid = xr.Dataset({\"lon\": ds_gcm.lon.values, \"lat\": ds_gcm.lat.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1893b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                 | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [01:55<00:00,  6.39s/it]\n"
     ]
    }
   ],
   "source": [
    "# get output grid\n",
    "ds_gcm = xr.open_dataset(f\"{base_dir}/raw_data/GFDL/GFDL_CM4C192_pr_hawaii_2007_2014.nc\")\n",
    "output_grid = xr.Dataset({\"lon\": ds_gcm.lon.values, \"lat\": ds_gcm.lat.values})\n",
    "\n",
    "# # load ERA5 data\n",
    "for year in tqdm(range(2007, 2025)):\n",
    "    filename = f\"{base_dir}/preprocessed_data/hourly_ERA5/ERA5_{year}.nc\"\n",
    "    ds_era5 = xr.open_dataset(filename)#, decode_cf=False)\n",
    "    input_grid = xr.Dataset({\"lat\": ds_era5.latitude.values, \"lon\": ds_era5.longitude.values})\n",
    "    regridder = xe.Regridder(input_grid, output_grid, 'conservative')\n",
    "    era5_regridded_3hourly = regridder(ds_era5.rename({'latitude': 'lat', 'longitude': 'lon'})).resample(time=\"3h\").mean()\n",
    "    era5_regridded_3hourly.to_netcdf(f\"{base_dir}/preprocessed_data/regridded_3hourly_ERA5/{year}.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8912f02",
   "metadata": {},
   "source": [
    "# Extract closest pixel, concat along years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ff93d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_data = pd.read_csv(f\"{base_dir}/raw_data/station_metadata.csv\")\n",
    "available_station_ids = [int(i.split('.')[0]) for i in os.listdir(f\"{base_dir}/preprocessed_data/selected_flowgauge_15mins\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e43423c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:49<00:00,  1.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(df_station_data[df_station_data['station_id'].isin(available_station_ids)].iterrows(), total=len(available_station_ids)):\n",
    "    all_year_data = []\n",
    "    # for year in range(2007, 2025):\n",
    "    for year in range(1974, 2025):\n",
    "        all_year_data.append(xr.open_dataset(f\"{base_dir}/preprocessed_data/regridded_3hourly_ERA5/{year}.nc\")['tp'].sel(lat=row.latitude, lon=row.longitude, method='nearest'))\n",
    "    xr.concat(all_year_data, dim='time').to_netcdf(f\"{base_dir}/preprocessed_data/station_ERA5/{row.station_id}.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa44f46",
   "metadata": {},
   "source": [
    "# Misc ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "877382e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [03:54<00:00,  4.60s/it]\n"
     ]
    }
   ],
   "source": [
    "# create non-gridded 3 hourly ERA5\n",
    "# # load ERA5 data\n",
    "for year in tqdm(range(1974, 2025)):\n",
    "    filename = f\"{base_dir}/preprocessed_data/hourly_ERA5/ERA5_{year}.nc\"\n",
    "    ds_era5 = xr.open_dataset(filename)\n",
    "    era5_3hourly = ds_era5.rename({'latitude': 'lat', 'longitude': 'lon'}).resample(time=\"3h\", offset='1h').mean()\n",
    "    era5_3hourly.to_netcdf(f\"{base_dir}/preprocessed_data/misc/original_grid_3hourly_ERA5/{year}.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffea1d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_data = pd.read_csv(f\"{base_dir}/raw_data/station_metadata.csv\")\n",
    "available_station_ids = [int(i.split('.')[0]) for i in os.listdir(f\"{base_dir}/preprocessed_data/selected_flowgauge_15mins\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d74648d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:39<00:00,  1.24s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(df_station_data[df_station_data['station_id'].isin(available_station_ids)].iterrows(), total=len(available_station_ids)):\n",
    "    all_year_data = []\n",
    "    for year in range(2007, 2025):\n",
    "        all_year_data.append(xr.open_dataset(f\"{base_dir}/preprocessed_data/misc/original_grid_3hourly_ERA5/{year}.nc\")['tp'].sel(lat=row.latitude, lon=row.longitude, method='nearest'))\n",
    "    xr.concat(all_year_data, dim='time').to_netcdf(f\"{base_dir}/preprocessed_data/misc/original_grid_3hourly_station_ERA5/{row.station_id}.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ef9b6",
   "metadata": {},
   "source": [
    "### Hourly ERA5 on original grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "390fcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_data = pd.read_csv(f\"{base_dir}/raw_data/station_metadata.csv\")\n",
    "available_station_ids = [int(i.split('.')[0]) for i in os.listdir(f\"{base_dir}/preprocessed_data/selected_flowgauge_15mins\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43605bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [02:41<00:00,  5.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, row in tqdm(df_station_data[df_station_data['station_id'].isin(available_station_ids)].iterrows(), total=len(available_station_ids)):\n",
    "    all_year_data = []\n",
    "    for year in range(2007, 2025):\n",
    "        all_year_data.append(xr.open_dataset(f\"{base_dir}/preprocessed_data/hourly_ERA5/ERA5_{year}.nc\")['tp'].rename({'latitude': 'lat', 'longitude': 'lon'}).sel(lat=row.latitude, lon=row.longitude, method='nearest'))\n",
    "    xr.concat(all_year_data, dim='time').to_netcdf(f\"{base_dir}/preprocessed_data/misc/original_grid_1hourly_station_ERA5/{row.station_id}.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b907ce6b",
   "metadata": {},
   "source": [
    "# GFDL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3003978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_data = pd.read_csv(f\"{base_dir}/raw_data/station_metadata.csv\")\n",
    "available_station_ids = [int(i.split('.')[0]) for i in os.listdir(f\"{base_dir}/preprocessed_data/selected_flowgauge_15mins\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b21f6ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [01:21<00:00,  2.53s/it]\n"
     ]
    }
   ],
   "source": [
    "filename = f\"{base_dir}/wasfia/GFDL_CM4C192_pr_hawaii_1981_2010.nc\"\n",
    "ds_gfdl = xr.open_dataset(filename)\n",
    "for i, row in tqdm(df_station_data[df_station_data['station_id'].isin(available_station_ids)].iterrows(), total=len(available_station_ids)):\n",
    "    ds_gfdl['pr'].sel(lat=row.latitude, lon=row.longitude, method='nearest').to_netcdf(f\"{base_dir}/preprocessed_data/station_cmip_historical/{row.station_id}.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
